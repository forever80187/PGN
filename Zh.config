# supervised transfer dataset #

# source domain
supervised_ner_1_train=/home/wen/NER_withACSent_0407_IO.train
supervised_ner_1_test=/home/wen/NER_withACSent_0407_IO.test
supervised_lm_1_train=/home/wen/NER_withACSent_0517.txt

# target domain
supervised_ner_2_train=/home/wen/Cross-Domain-NER/ZhDataset/SA_data/fold_0_2.train
supervised_ner_2_test=/home/wen/Cross-Domain-NER/ZhDataset/SA_data/fold_0_2.test
supervised_lm_2_train=/home/wen/Cross-Domain-NER/ZhDataset/LM_singer/SINGER_LM_21K.txt

# word embed vocab:
word_embed_dir=/home/wen/Cross-Domain-NER/ZhDataset/Emb_Glove/for_glove_vectors.txt

batch_size=30
task_emb_dim=8
domain_emb_dim=8

Ren=False
HIGHWAY=False
MESSAGE=False

W1=0.8
W2=1
W3=0.5
W4=0.5

# check point #
model_dir=data/check_point/cross_ner_model
init_dir=data/check_point/cross_ner_init

# normalize
norm_word_emb=False
#norm_char_emb=False
number_normalized=True

# network parameter #
MAX_SENTENCE_LENGTH=128
MAX_WORD_LENGTH=16
seg=True

word_emb_dim=300
#char_emb_dim=30

#cnn_layer=4
#char_hidden_dim=50
hidden_dim=200 
dropout=0.5
lstm_layer=2
bilstm=True

use_ner_crf=True
#use_char=False

#char_seq_feature=CNN

status=train
mode=supervised
optimizer=SGD
iteration=500
ave_batch_loss=True

learning_rate=0.015
learning_rate_cpg=0.005
lr_decay=0.05
momentum=0
l2=1e-8
gpu=True